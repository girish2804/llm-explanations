{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with Explanations\n",
    "\n",
    "This notebook demonstrates refactored sentiment analysis with LIME and SHAP explanations.\n",
    "The code has been modularized for better maintainability and includes fidelity testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q lime datasets transformers accelerate bitsandbytes sentencepiece shap matplotlib seaborn\n",
    "\n",
    "# Import necessary modules\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Refactored Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our custom modules\n",
    "from config import ExplanationConfig, DatasetConfig, SentimentLabel\n",
    "from sentiment_analyzer import SentimentAnalyzer\n",
    "from data_handler import DataHandler\n",
    "from explanation_generator import ExplanationGenerator\n",
    "from explanation_tester import ExplanationTester"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the sentiment analyzer\n",
    "analyzer = SentimentAnalyzer()\n",
    "print(f\"Device: {analyzer.get_device_info()}\")\n",
    "\n",
    "# Initialize data handler\n",
    "data_handler = DataHandler()\n",
    "print(f\"Dataset info: {data_handler.get_dataset_info()}\")\n",
    "\n",
    "# Initialize explanation generator\n",
    "explainer = ExplanationGenerator(analyzer)\n",
    "\n",
    "# Initialize explanation tester\n",
    "tester = ExplanationTester(analyzer, explainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Basic Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample data\n",
    "sample_texts = data_handler.get_test_texts(0, 3)\n",
    "sample_labels = data_handler.get_test_labels(0, 3)\n",
    "\n",
    "print(\"Sample predictions:\")\n",
    "for i, (text, true_label) in enumerate(zip(sample_texts, sample_labels)):\n",
    "    prediction = analyzer.predict_single(text)\n",
    "    probabilities = analyzer.predict_proba([text])[0]\n",
    "    \n",
    "    print(f\"\\nSample {i}:\")\n",
    "    print(f\"Text: {text[:100]}...\")\n",
    "    print(f\"True label: {true_label}\")\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "    print(f\"Probabilities [positive, negative]: {probabilities.round(3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LIME Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate LIME explanation for a specific sample\n",
    "explanation_index = 22\n",
    "sample_data = data_handler.get_test_sample(explanation_index)\n",
    "\n",
    "print(f\"Generating LIME explanation for document {explanation_index}\")\n",
    "print(f\"Text: {sample_data['text'][:200]}...\")\n",
    "print(f\"True label: {sample_data['label']}\")\n",
    "\n",
    "# Get comprehensive explanation summary\n",
    "explanation_summary = explainer.get_explanation_summary(\n",
    "    sample_data['text'], \n",
    "    explanation_index, \n",
    "    sample_data['label']\n",
    ")\n",
    "\n",
    "print(f\"\\nPrediction: {explanation_summary['prediction']}\")\n",
    "print(f\"Probabilities: {explanation_summary['probabilities']}\")\n",
    "print(f\"LIME explanation: {explanation_summary['lime_explanation']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display LIME explanation in notebook\n",
    "lime_explanation = explainer.explain_instance_lime(sample_data['text'])\n",
    "lime_explanation.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. SHAP Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get background texts for SHAP\n",
    "background_texts = data_handler.get_test_texts(0, 20)\n",
    "\n",
    "# Generate SHAP explanation\n",
    "print(f\"Generating SHAP explanation for document {explanation_index}\")\n",
    "shap_explanation = explainer.explain_instance_shap(\n",
    "    sample_data['text'], \n",
    "    background_texts\n",
    ")\n",
    "\n",
    "if shap_explanation is not None:\n",
    "    print(\"SHAP explanation generated successfully\")\n",
    "    # You can add SHAP visualization here if needed\n",
    "    # shap.plots.text(shap_explanation)\n",
    "else:\n",
    "    print(\"SHAP explanation not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Submodular Pick Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate submodular explanations\n",
    "sample_texts_for_sp = data_handler.get_test_texts(0, 10)\n",
    "\n",
    "print(f\"Generating submodular explanations for {len(sample_texts_for_sp)} texts\")\n",
    "sp_obj = explainer.generate_submodular_explanations(\n",
    "    sample_texts_for_sp,\n",
    "    sample_size=3,\n",
    "    num_features=6,\n",
    "    num_explanations=2\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(sp_obj.sp_explanations)} submodular explanations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display submodular explanation plots\n",
    "figures = [exp.as_pyplot_figure() for exp in sp_obj.sp_explanations]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display labeled explanation plots\n",
    "labeled_figures = [\n",
    "    exp.as_pyplot_figure(label=exp.available_labels()[0]) \n",
    "    for exp in sp_obj.sp_explanations\n",
    "]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Explanation Fidelity Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test explanation fidelity\n",
    "test_texts = data_handler.get_test_texts(0, 20)\n",
    "\n",
    "print(f\"Testing explanation fidelity on {len(test_texts)} samples...\")\n",
    "fidelity_results = tester.test_batch_fidelity(test_texts, sample_size=10)\n",
    "\n",
    "# Generate and display report\n",
    "report = tester.generate_fidelity_report(fidelity_results)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detailed fidelity results\n",
    "print(\"Detailed fidelity results for first 3 tests:\")\n",
    "for i, detail in enumerate(fidelity_results.details[:3]):\n",
    "    print(f\"\\nTest {i+1}:\")\n",
    "    print(f\"  Original text: {detail['original_text'][:100]}...\")\n",
    "    print(f\"  Original prediction: {detail['original_prediction']}\")\n",
    "    print(f\"  Supporting fidelity: {detail['supporting_fidelity']}\")\n",
    "    print(f\"  Contrary fidelity: {detail['contrary_fidelity']}\")\n",
    "    print(f\"  Top features: {detail['top_features']}\")\n",
    "    print(f\"  Supporting text: {detail['supporting_text'][:100]}...\")\n",
    "    print(f\"  Contrary text: {detail['contrary_text'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fidelity visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Fidelity scores\n",
    "fidelity_types = ['Supporting', 'Contrary', 'Average']\n",
    "fidelity_scores = [\n",
    "    fidelity_results.supporting_fidelity,\n",
    "    fidelity_results.contrary_fidelity,\n",
    "    fidelity_results.average_fidelity\n",
    "]\n",
    "\n",
    "bars = ax1.bar(fidelity_types, fidelity_scores, color=['green', 'red', 'blue'])\n",
    "ax1.set_title('Explanation Fidelity Scores')\n",
    "ax1.set_ylabel('Fidelity Score')\n",
    "ax1.set_ylim(0, 1)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, score in zip(bars, fidelity_scores):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "             f'{score:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Probability differences distribution\n",
    "supporting_diffs = [detail['supporting_prob_diff'] for detail in fidelity_results.details]\n",
    "contrary_diffs = [detail['contrary_prob_diff'] for detail in fidelity_results.details]\n",
    "\n",
    "ax2.hist(supporting_diffs, alpha=0.7, label='Supporting', bins=10)\n",
    "ax2.hist(contrary_diffs, alpha=0.7, label='Contrary', bins=10)\n",
    "ax2.set_title('Probability Difference Distribution')\n",
    "ax2.set_xlabel('Probability Difference')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Analysis Summary ===\")\n",
    "print(f\"Total samples analyzed: {len(sample_texts)}\")\n",
    "print(f\"Explanations generated: {len(sp_obj.sp_explanations)}\")\n",
    "print(f\"Fidelity tests conducted: {fidelity_results.num_tests}\")\n",
    "print(f\"Overall explanation quality: {fidelity_results.average_fidelity:.3f}\")\n",
    "\n",
    "if fidelity_results.average_fidelity >= 0.8:\n",
    "    print(\"✅ Explanation quality is HIGH\")\n",
    "elif fidelity_results.average_fidelity >= 0.6:\n",
    "    print(\"⚠️ Explanation quality is MODERATE\")\n",
    "else:\n",
    "    print(\"❌ Explanation quality is LOW\")\n",
    "\n",
    "print(\"\\nKey improvements in this refactored version:\")\n",
    "print(\"- Modular architecture with separate concerns\")\n",
    "print(\"- Proper error handling and logging\")\n",
    "print(\"- Configuration management with enums\")\n",
    "print(\"- Comprehensive testing framework\")\n",
    "print(\"- Support for both LIME and SHAP explanations\")\n",
    "print(\"- Fidelity testing for explanation quality\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}